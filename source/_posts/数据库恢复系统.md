---
title: 事务篇四：Log-Based Recovery System
date: 2022-06-22 11:55:46
tags:
categories:
- [事务]
math: true
sticky: 1
---

## 前言
![磁盘交互模型](/img/log-based_recovery_system/1.png)
事务的原子性和一致性（数据库数据一致性）的保证，除了在事务代码的编写（逻辑）、事务的调度（并发）上面下功夫外，还需要考虑系统故障的发生。当系统从故障中恢复后，应当正确处理这些异常，以保证事务的原子性和数据的一致性。

<font color=dark-green>一个例子</font>

考虑银行有两个账户 A 和 B，初始账户分别为 1000 和 2000，一个事务负责从账户 A 转账 50 到账户 B。假设故障发生在事务执行过程中，那么有如下可能发生：
1. A = 950, B = 2050
2. A = 950, B = 2000
3. A = 1000, B = 2050
4. A = 1000, B = 2000

根据磁盘交互模型图可知，事务需要先将需要的数据从 buffer pool 读入自己的私有内存，等到操作完成再将更新后的数据写入 buffer pool，至于这些数据何时会写入磁盘与 buffer pool 页面置换算法有关。上面情况 1 表示一切正常；情况 2 表示含有 A 新值的 block 被正常写入磁盘后系统崩溃；情况 3 表示含有 B 新值的 block 被正常写入磁盘后系统崩溃；情况 4 表示两个 block 都还未写入磁盘就发生故障（当然 A 和 B 可能存在于同一个 block 中）。在情况 2 和 3 中数据库一致性都已被破坏，事务的原子性也未能保证。

## Log-Based Recovery System
为了保证事务的原子性和数据的一致性，需要一种方法从故障中恢复被部分修改的数据，目前最广泛使用的方式是：**在更新数据库之前，先将描述修改的信息记录到 stable storage 中的 log 文件里**，等到系统重启后，根据这些信息来恢复数据。这些信息被称为 log records，这个方法被称作 log-based recovery.

### Log Records & 事务流程
当事务开始时，会向日志中追加一条事务**开始记录** <$T_i\\ $start>，$T_i$ 表示事务标识符；在将更新写入数据库之前，会向日志中追加一条**更新记录** <$T_i,\\ X_j,\\ V_1,\\ V_2$>，$X_i,\\ V_1,\\ V_2$ 分别表示数据标识符（通常用磁盘块号和偏移量）、该数据的旧值和新值；等到事务提交时，会向日志中追加一条**提交记录** <$T_i\\ $commit>，如下面例子：
![图 2](/img/log-based_recovery_system/2.png)
一旦这些记录被写入了日志文件中，系统就可以将事务的修改应用到数据库中了，就算故障发生，也能根据日志文件重放（replay）这些操作，恢复它们，正因为如此，日志文件必须持久化（写入 stable storage，定义见{% post_link 事务总论 %}），以保证永久不丢失。需要注意，$T_0,\\ T_1$ 的日志记录可能是相互交叉的。

现在在细节上更进一步，所谓的将记录追加到日志文件中、更新写入数据库中这些操作实际上包含两个步骤：
1. 将事务私有内存空间的数据写入某个 buffer block；
2. 将 buffer block 写到磁盘上。

第二步由数据库系统执行，发生的时机是不定的，**所以当第一步发生后，就算是对文件和数据库做出了修改**。需要明白，buffer block 中的数据可能会在内存中存在很长一段时间才会被写入磁盘（当然可以让第二步即时生效，但磁盘 I/O 代价昂贵，非必须，一般是推迟写磁盘），在这段时间内系统完全有可能发生故障，所以事务提交流程中有一些<font color=red>原则（write-ahead logging, WAL, rule）必须要遵守，以保证事务的原子性</font>：
* 事务已提交是指（可以回复客户端了），提交记录 <$T_i\\ $commit> 已经被 *output* 到 stable storage 中。
* 在上一步执行之前，该事务的所有其他记录（存在于 log buffer 中）都被 *output* 到 stable storage 中。
* 在数据被 *output* 到数据库之前，与这些数据更新相关的所有日志记录都已经被 *output* 到 stable storage 中。

只要遵守了以上原则，无论是系统崩溃后恢复还是事务的正常 abort，系统都可以根据这些记录将系统恢复到一致状态，事务自然也就保证了原子性。因此日志记录在 log 文件（stable storage）中的**顺序十分重要**，必须和写入 log buffer（buffer block）的顺序一致。

### Recovery Algorithm
在介绍恢复算法之前，先看看事务在正常情况下的流程，第一种是事务因失败需要 abort 回滚；第二种是事务正常提交。

**Case 1: 事务正常提交**。这种情况下事务不需要回滚，日志文件就像图 2 所示那样。

**Case 2：正常 abort，事务回滚**。当事务 $T_i$ 执行到一半时因为某些原因失败需要 abort 回滚（rollback 之后才能算 aborted）。回滚也就是将该事务对数据库所做的修改撤销，系统做如下操作（如图 3 示）：
* 系统向后扫描 log 文件（注意 log 文件是只追加的，向前是指追加的方向），对于每一条属于 $T_i$ 的更新记录 <$T_i,\\ X_j,\\ V_1,\\ V_2$>，系统将使用旧值 $V_1$ 更新 $X_i$ （即撤销修改），同时向日志追加一条 redo-only 记录 $<T_i,\\ X_j,\\ V_1$>。
* 当遇到记录 <$T_i\\ $start>，系统向日志追加一条 <$T_i\\ $abort> 记录，对于该事务的回滚也就结束了。

系统回滚所添加的这些日志记录又被称为 compensation log records. 其实可以这样理解，事务中止处于未完成状态，系统创建一个互补事务，负责撤销事务所做的更改，并补充完整日志记录。

![图 3](/img/log-based_recovery_system/3.png)


<br>

<font color=dark-green>恢复算法思想</font>
系统重启后是很懵逼的，它不清楚执行过的事务的具体情况，所以它需要查看 log 文件，根据日志记录的完整性，可以将事务分为两种：
* <u>事务执行完成（committed 或 aborted）</u>。当系统重启后，发现某事务在 log 文件中包含了完整的日志记录，同时具有 <$T_i\\ $start> 和 <$T_i\\ $commit> 或 <$T_i\\ $abort>。根据 WAL rule，尽管日志表明该事务已经完成，无论是事务自己正常提交还是系统所做的互补操作，但它不能确定这些操作已经写入数据库中（很可能系统在将 log buffer *output* 到 stable storage 之后就失败了，还未来得及将 data buffer *output* 到数据库），**因此它必须依据日志 redo 这些操作**。

* <u>事务执行未完成</u>。当系统重启后，发现某事务在 log 文件中没有包含完整的日志记录，即缺少了 <$T_i\\ $commit> 或 <$T_i\\ $abort> 记录，为保证事务的原子性和数据的一致性，该事务所做的操作必须撤销，**也就是必须 undo 这些操作**。当然，系统有可能在 rollback 未完成时就发生了故障，也就是日志中含有不完整的 redo-only 记录，undo 这些记录实际上就是 redo 它们。

上面简单描述了恢复算法的的思想，很朴素，<font color=red>但却存在很大的性能问题</font>，试想在系统重启之前可能存在成千上百的事务执行大量的操作，这些操作都记录在了 log 文件中，log 文件可能变得十分巨大，若系统重启后对这些操作全都执行 redo 或 undo，系统可用性就会很差，何况，有很多操作已经实实在在写入了数据库，不需要再做额外的操作。为了减少恢复时间，数据库系统通常采用一种简单的方法，称作 checkpoints. 

<br>

<font color=dark-green>Checkpoints 思想</font>
checkpoint 是一组如下的操作：
1. 从 log buffer *output* 所有的日志记录到 stable storage 中。
2. 从 data buffer *output* 所有的数据修改到数据库磁盘文件中。
3. 系统向日志文件追加一条 \<checkpoint L\> 记录，并 *output* 到 stable storage 中。L 是一组事务标识符的集合，表示执行 checkpoint 时，还处于活跃状态的事务集合。 

<font color=red>那么有了 checkpoint 后，又当如何缓解上述问题呢？</font>假设存在一个事务 $T_i$，它在执行 checkpoint 操作之前已经完成（committed 或 aborted），那么该事务的相关日志记录要么在 checkpoint 之前 *output* 到日志文件了，要么在 checkpoint 过程中 *output* 到日志文件，总之这些记录出现在 \<checkpoint L\> 之前，即 L 中不包含 $T_i$，系统重启后，也自然没有必要 redo $T_i$ 的操作了。随着日志文件越来越大，有了 checkpoint 记录，就可以丢弃以前的记录了，反正也用不上了。

<br>

<font color=dark-green>恢复算法详细步骤</font>
有了以上的知识背景，现在可以提出完整的 log-based recovery algorithm 步骤了，当数据库系统从崩溃中重启后，会完成如下两个部分的工作：

**重放阶段（Redo Phase）**. 该阶段，系统从最后一条 checkpoint 记录开始<font color=red>向前扫描</font>（追加方向），重新执行具有完整日志记录（含有 commit 或 abort 记录）的事务所做的操作。另外，该阶段在扫描时，还会记录 undo-list，包含那些没有完整记录（不含有 commit 或 abort 记录）的事务标识符，这些事务要么出现在最后一条 checkpoint 记录的 L 中，要么在最后一次 checkpoint 操作后才开始。在扫描过程中，有如下步骤：
1. 使用最后一条 checkpoint 记录中的 L 集合初始化 undo-list
2. 当扫描到一条更新记录 <$T_i,\\ X_j,\\ V_1,\\ V_2$> 或者 redo-only 记录 <$T_i,\\ X_j,\\ V_1$> 时，系统重新执行记录表示的操作。
3. 当扫描到一条 <$T_i\\ $start> 记录时，将 $T_i$ 添加到 undo-list 中。
4. 当扫描到一条 <$T_i\\ $commit> 或 <$T_i\\ $abort> 记录时，将 $T_i$ 从 undo-list 中移除。

**撤销阶段（Undo Phase）**. 上一阶段结束后，undo-list 包含了所有处于未完成状态的事务标识符。系统从日志文件结束位置开始<font color=red>向后扫描</font>，撤销这些未完成事务的所有操作，扫描中，包含如下步骤：
1. 当扫描到属于 undo-list 中事务的日志时，执行 undo 操作，和正常情况下事务失败回滚的操作一样。
2. 当扫描到属于 undo-list 中事务的 <$T_i\\ $start> 日志后，系统向日志文件追加一条 <$T_i\\ $abort>，并将该事务从 undo-list 中移除。
3. 当 undo-list 为空时，扫描停止，该阶段结束。

在 redo 阶段可能存在重复的操作，比如正常情况下的失败事务的日志记录和回滚时的记录，但正是这少许的重复，使得整个流程简单了不少，只需要两遍扫描就能完成恢复。上述两个过程如图 4 所示：
![图 4](/img/log-based_recovery_system/4.jpg)


<br>

<font color=dark-green>一些细节</font>
checkpoint 阶段应该也是原子操作，也就是说，在执行 checkpoint 时，不允许事务向 buffer 中写更新，这个要求可以通过 fuzzy checkpoint 技术放松，这里不谈。

而且，当 buffer block 向磁盘 *output* 时，也不允许事务向 buffer block 执行写操作，不然可能会违法 WAL 规则。

保证以上两个要求，可以通过特殊的锁：
* 当事务执行 *write* 时，应当先获取数据所在 buffer block 的排它锁，当更新执行完后，立即释放锁。
* 当 *output* data buffer block 时，应该先获取 该 block 的排它锁，然后 *output* 与该 block 数据相关的所有 log records 到 stable storage 中，再然后 *output* 该 block 的数据到数据库磁盘文件中，最后释放该锁。

可以看到，这里的锁持有的时间很短，一般将这种锁称为 latch.


## 总结
虽然写了这么多，但这些却是最简单的知识，还有很多高级的话题没写，等着以后学习深入了再来补充吧。