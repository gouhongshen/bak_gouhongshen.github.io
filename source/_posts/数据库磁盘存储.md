---
title: 关系型数据库磁盘存储
date: 2022-06-29 18:43:25
tags:
- [数据库文件存储]
categories:
- [数据库]

math: true
sticky: 1
---

## 前言
本文主要介绍关系型数据库的一张表在磁盘中是如何存储的。

绝大多数数据库系统将一张表（relation）存储在一个或多个文件中（file），由于 file 可能很大，为方便元组（tuple，也称 record）的增删改查，file 内部又被分为了多个 page（或 block，一般 4KB-8KB），真正的元组存储在 block 中。同时 block 也是内存和磁盘之间的数据传输单位。

以上的结构都是逻辑结构，存储在磁盘时，通常会由多个物理块（比如扇区）连续存储，来表示一个 block.

后面会依次介绍元组如何组织各个属性值，block 如何存储元组，以及 file 对元组的管理。

## 属性值在元组中的存储
假设创建如下的表：
![](/img/storage_in_disk/1.jpg)
该表的四个属性有三个是变长的，最简单的一种方式是给每个属性值都分配其声明的最大值，在该例子中为 53 bytes。很多时候，属性值并不能达到其要求的上限，而且还可能存在 null 值，十分浪费空间。

为满足属性值变长特性，通常采用如下的方式组织一个元组内部的值：
![](/img/storage_in_disk/2.png)
整个元组分为两部分：头部（header）和实际的数据存储部分，header 用来存储一些元数据，若表的模式确定，其头部大小也就固定了：
* <u>空值位图（null bitmap）</u>。除了主键外，其他属性值可能会为 null，空值位图用每一位来表示某一属性值是否为空，若为空该位置 1. 在一些实现中，若属性值为空，则不分配空间，适合空值较多的表；一些实现中，若为空，依然分配空间，读取时忽视即可，如例子（例子中空值位图没有放置在最前面）。
* <u>各属性值的偏移与大小数组</u>。由于属性值可能是变长的，所以需要同时记录这些属性值在该元组中的偏移量和大小，如例子（例子中，内存占用固定的 salary 属性值放置在该数组后面）。
* <u>可见性标识</u>。用于并发控制，一般是锁标志。

数据部分的 a, b, c, d 就是实际的属性值。对于大对象的存储，比如图片、视频等，属性值会保存一个指针（如指向另外一个 file 或者 page），然后将大对象存储在其他地方。

**注意**，头部并没有存储表模式信息（schema），因为如何解析一条元组的数据是由数据库上层决定的。当一张表被创建时，其模式信息就保存在了数据库元信息中，当读取一条元组时，就依据这些元信息来解析元组中各属性值。


## 元组在 block 中的存储
在 block 中存储元组（tuple/record），slotted-page structure 是用得最多的一种结构，如下图：
![](/img/storage_in_disk/3.png)

可以看出也分为头部 header 和数据部分，头部包含三个部分：
* <u>Record 的数量</u>。也就是元组的数量。
* <u>空闲空间的结束位置</u>。在插入元组时，由该位置能快速找到空闲空间放置元组。
* <u>记录 Record 偏移和大小的 Entry 数组</u>。由于元组的属性值变长，所以尽管属于同一张表，元组同样是变长的，该数组能方便的提取元组。

当往一个 block 中插入一条 record 时，首先检查空闲空间能否放下该 record（由图很容易计算），若有，则从空闲空间的最后一个字节开始**往头部移动**分配空间给该 record，同时插入一个 entry.

当从一个 block 中删除一条 record 时，会将指向该记录的 entry 设置为删除（比如将 size，图中 y，设置为 -1），然后移动那些后面插入的 record 覆盖删除的 record。由于总的 record 数量不算太多，移动的代价还能接受。


## 元组在文件中的组织方式
一张表包含一系列元组，由单个或多个文件（如分表）组成，而一个文件又可能存在多个 block，上一节是介绍元组在 block 中如何存储，这一节则是介绍如何为元组选取合适的 block.

### 堆文件组织方式
![](/img/storage_in_disk/8.png)
> pages 相当于 blocks

堆文件（heap file）组织方式中，总是将 record 放置到有空闲空间的 block 中（如第一个有空闲空间的 block）。在寻找具有空闲的 block 时，为了避免按顺序扫描所有的属于该文件的 block，绝大多数数据库采用了 free-space map 的结构。

free-space map 通常是一个整数数组，一个数组元素对应表的一个 block，元素的值与 block 空闲空间比例有关系，该数组存储在某个 block 中，一般在一开始就读进了内存中。如下例子：
![](/img/storage_in_disk/4.jpg)

假设某个表具有 16 个 block，因此 free-space map 具有 16 个元素。假如使用 3-bit 来表示一个数组元素，那么将某个元素存储的值除以 $2^3$ 就能得到该 block 中空闲空间（至少）占据的比例，如元素值为 7 表示该 block 至少有 7/8 的比例是空闲的。为何是这样？如果直接存储 $f = \frac{block\\_free\\_space}{block\\_total\\_space}$ 那么都会为零，所以，存储的实际是 $f*2^n$，$2^n$ 表示该元素能表示的最大的数，如 PostgreSQL 就采用的 8-bit free-space map.

如果表很大，那么 block 数量也可能很大，free-space map 也就可能很大，为了进一步减少扫描的时间，可以采用多级 free-space map 结构，如下，采用两级：
![](/img/storage_in_disk/5.png)
很好理解，其实就是将第一级分组，然后选出其中最大的构成第二级，类似折半查找，如果第二级数量依旧庞大，可以继续分下去。

每当插入元组后，block 的空闲空间比例可能会变小，free-space map 结构也就需要更新，更新的 free-space map 存在于内存中，所以需要将其写入磁盘。然而，每次更新都写磁盘代价高昂，一般采用延迟写（周期性），这样就会导致磁盘的文件过时，若未来得及写磁盘就发生了故障，重启后，free-space map 就记录了过时的数据。不过，这没啥大不了的问题，数据过时导致查找的 block 与实际不符，多来几次也就将过时的信息更新了，当然也可以周期性的扫描 block 来更新该结构。


### 序列文件组织方式
考虑到这样一种场景，某些记录总是以某种方式频繁检索，如某个年龄区间 + 性别，为了实现这样的高效检索，记录一般以检索键（search key）顺序存储。search key 由任何属性或一组属性构成，不一定是主键。

为了使得它们按 search key 顺序存储，每条记录还会存储下一条记录的位置（指针），检索时按照该指针就能快速检索相关记录；插入时，需要找到该记录的前一条记录，然后修改指针即可；删除时也需要修改指针。这些操作和链表一致。例子如下图：
![](/img/storage_in_disk/6.jpg)

比如，若插入一条记录，则可以按照如下方式：
* 定位待插入记录的前一条记录所在的 block. 可以通过记录每个 block 中最大最小 search key 做到。
* 如果该 block 有空闲空间，插入，并修改相应的指针，若无，则插入一个 overflow block（就如图片展示的那样），并修改指针。


### 散列文件组织方式
哈希结构通常用在内存中存储数据，它的特点是能够快速定位记录的位置。在内存中，哈希通常是一个指针数组，每个指针是一个链表头，该链表存储定位到该数组元素的实际数据（链地址法），比如数据库在内存中的哈希索引结构。而在 disk-based 哈希中，哈希结构一个 bucket（可以理解为 block） 数组，每个 bucket 存储实际的记录。

当插入一条记录时，计算该记录的哈希值，$buket\\_idx = h(r\\_key)\\ \\%\\ buket\\_num$，然后再将记录插入该 bucket，若 bucket 满了，那么就会新分配一个 bucket 链接在后面作为 overflow bucket，将记录插入新的 bucket 中。

当查找某条记录时，采用同样的方式计算 bucket_idx，然后在 bucket 及其 overflow bucket 中查找（一般是顺序检索）是否存在。具体结构如下：
![](/img/storage_in_disk/7.png)

之所以会出现 overflow bucket，有以下原因：record_key 分布不均匀，或者是哈希函数选择得不够好，导致某些 bucket 记录特别多，而有些又特别少。一般通过选取好一点的哈希函数，或者通过分配更多 bucket 缓解（如 bucket_num = $(n_r / f_r) * (1 + d)$，$n_r, f_r$ 分别表示总的记录数和每个 bucket 能够存储的记录数，d 表示一个经验系数，一般取 0.2）。而 record 的数量很多时候根本无法预估，固定分配的哈希结构（static hashing），就可能不能适应记录数量的增减，一般有以下方式解决：
* rehashing. 此方法需要重新计算所有的记录，比较耗时。
* dynamic hashing. 具体见{% post_link "索引篇一：哈希索引" %}
* 采用其他结构。


### B+ tree 文件组织方式
B+ tree 文件组织方式，见 {% post_link "索引篇二：B-plus Tree" %}








