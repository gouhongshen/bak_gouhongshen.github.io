---
title: 数据的复制
date: 2022-08-12 16:00:19
tags:
---

所谓的复制其实就算数据在多个节点上的冗余存储，这些节点一般通过网络连接（内部网络-单个数据中心内；公共网络-跨数据中心）。一般来说，数据冗余存储有如下优点：
* 增强数据的可用性和安全性。如果某个节点发生故障，依然能向外提供数据服务。
* 减少请求响应时间。不同的请求路由到邻近的副本处理。
* 增加吞吐量。请求可以分配到不同的副本处理，减轻单个节点的负载。

<br>

> 数据复制的单位通常是数据分片，如 tablet、node、virtual node 等。

<br>

下面介绍三种常用的复制类型：单主复制（single-master）、多主复制（multi-master）和无主复制（leaderless）。

## 单主复制
单主复制又叫主从复制，在所有副本中选择一个作为主节点，其余的副本称为从节点或从库。客户端的**写请求必须发送到主节点**（若从节点收到写请求，可以路由给主节点），从节点可以处理读请求，从客户端的角度来看从节点都是只读的。这样的配置称之为单活。

主节点接收客户端的写请求后，除了将数据写入本地存储外，还需要将新数据复制到从节点以保证副本一致性。复制方式可以分三类：
* **同步复制（synchronous replication）**。该模式下，主节点执行完一个写请求（或一个事务）后，必须等待所有同步从节点都复制了更新后，才可以回复客户端写入成功。同步复制的<u>优点是</u>，从节点保证有与主节点一致的最新数据副本。如果主节点突然失效，这些数据仍然能在从节点上上找到。<u>缺点是</u>，如果同步从节点没有响应（比如它已经崩溃，或者出现网络故障，或其它任何原因），主节点就无法处理写入操作。主节点必须阻止所有写入，并等待同步副本再次可用。
* **异步复制（asynchronous replication）**。在模式下，主节点执行完写请求后，会将新数据复制给从节点，但无需等待其他副本写入成功就返回客户端。很明显，异步复制的<u>优点是</u>，主节点不需要等待从节点，所以写请求响应快。<u>但是</u>，异步复制会潜在地影响副本数据的一致性和持久性。例如，如果客户端收到写请求完成响应后立即查询刚刚写入的数据则有可能读到旧值（或不存在），这可以通过实现读己之写一致性避免。再如，如果主节点还未复制新数据到从节点时就发生不可恢复故障，那么数据就有可能永久丢失。
* **半同步复制（semisynchronous replication）**。在该模式下，主节点只需要等待至少一个从节点复制更新后才返回，不需要等待所有从节点。

<br>

> 将所有从节点都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。实际上，如果在数据库上启用同步复制，通常意味着其中一个跟随者是同步的，而其他的则是异步的，也就是半同步。如果同步从节点变得不可用或缓慢，则可以将某一个异步从节点提升为同步从节点，可以保证至少在两个节点上拥有最新的数据副本。

> 异步复制能提供比较好的性能，但存在数据丢失的风险，所以学界工业界一直在寻找不丢数据但仍能提供良好性能和可用性的复制方法，比较成功的有[链式复制](https://pdos.csail.mit.edu/6.824/papers/cr-osdi04.pdf)和{% post_link "raft-杂记" 共识协议 %}。

> 引入数据多副本后，客户端的请求会涉及到一致性问题，具体可以参见文章：{% post_link "分布式一致性模型" %}。另外，主节点采用什么方式将数据复制给从节点呢？这个还是得以一个具体得数据库为例弄清楚比较好，参见文章：{% post_link "MySQL 的复制" %}。

总的来说，**单主复制的主要优点有**：① 简单易懂、易于实现；② 仅在主节点执行（并发）写请求，能够保证操作的顺序性，避免了副本数据冲突的麻烦，当然了单主场景也会发生冲突，比如切换主节点后原主节点的数据与当前主节点冲突，解决方法当然是以当前主节点数据为准。这个特性使得单主复制更容易支持事务类操作，因为简单，性能高；③ 对于大量读请求工作负载的系统，单主复制是可拓展的，通过增加从节点就能提高读事务吞吐量。

**缺点也很明显**：① 面对大量写请求工作负载时系统很难进行拓展，因为写请求的瓶颈在主节点；② 主节点宕机时，从节点切换是一个难题。节点切换可以有手动切换和自动切换两种。对于手动切换能保证新主节点具有完整的数据，但耗时长；对于主动切换则可能发生脑裂，比如在网络分区中，多个从节点检测到主节点失效同时成为新的主节点，当然了共识协议可以解决这个问题。

## 多主复制 
所谓多主复制就是指在副本中存在多个主节点，复制仍然以同样的方式发生：处理写入的每个主节点都必须将该数据更改转发给所有其他节点。 称之为多领导者配置（也称多主、多活复制）。在这种情况下，每个主节点同时扮演其他主节点的从节点。
> 这里需要注意，数据分片后，每个分片都会有一个主节点，这种场景应该不是多主复制，因为这些主节点负责的数据没有交集，不存在冲突一说。

![](/img/data_replication/2.png)

因为好处很少超过复杂性的代价，在单个数据中心内部基本不使用多主配置，在一些情况下，多活配置也是合理的：**① 多数据中心**。假如有一个数据库，副本分散在好几个不同的数据中心（也许这样可以容忍单个数据中心的故障，或地理上更接近用户）。 使用常规的基于领导者的复制设置，主节点必须位于其中一个数据中心，且所有写入都必须经过该数据中心。多领导者配置中可以在每个数据中心都有主节点。
> 如果是单活配置，每个写入都必须穿过互联网，延迟会很高，违背了多数据中心的一部分初衷（就近原则）；若是多活配置，各写入可以路由到最近的数据中心，各数据中心采用异步复制，提升写性能。

> 如果是单活配置，若数据中心故障，跨数据中心的主节点选举耗时更长；若是多活配置，各数据中心独立运行，不受影响。

> 如果是单活配置，同步复制可能会跨数据中心，走公共网络，远不如内部的网络可靠；若是多活配置，异步复制更能容忍网络故障。

**② 离线操作的客户端**。应用程序在断网之后仍然需要继续工作，在这种情况下，每个设备都有一个充当领导者的本地数据库（它接受写请求），并且在所有设备上的副本之间同步时，存在异步的多主复制过程。从架构的角度来看，这种设置实际上与数据中心之间的多领导者复制类似，每个设备都是一个“数据中心”，而它们之间的网络连接是极度不可靠的。**③ 协同编辑**。当一个用户编辑文档时，所做的更改将立即应用到其本地副本（Web 浏览器或客户端应用程序中的文档状态），并异步复制到服务器和编辑同一文档的任何其他用户。

![](/img/data_replication/1.png)
一般来说，通过 IP 属地、地理位置等可以将特定用户/客户端的请求路由到同一个主节点（数据中心），能在一定程度上避免数据冲突，但有些情况依然有可能会发生冲突，比如负载均衡、多用户操作同一数据等，如上图。一些常见的数据冲突解决方法有：
* **由客户端解决**。具体方案是，当（主节点间）异步复制发现数据冲突时将所有冲突的数据都保留下来（多个版本）。客户端下次读取发生冲突的数据时，将所有数据版本都返回给客户端，由客户端选择合适的数据再返回给主节点覆盖冲突的数据。购物车就是一个典型的例子。购物车应用解决冲突的逻辑是保留购物车中所有冲突的商品，并返回给用户，当用户看到重复的或已经被删除的物品，就会主动纠正，纠正后的内容被重新提交，就解决了该冲突。
* **最后写入胜利**。给每个写入一个唯一的 ID（例如，一个时间戳，一个长的随机数，一个 UUID 或者一个键值的哈希），挑选最高 ID 的写入作为胜利者，并丢弃其他写入。如果使用时间戳，这种技术被称为最后写入胜利（LWW, last write wins）。虽然这种方法很流行，但是很容易造成数据丢失。
* **特殊的数据类型**。如无冲突复制数据类型（conflict-free replicated datatypes，CRDT）是可以由多个用户同时编辑的集合，映射，有序列表，计数器等的一系列数据结构，它们以合理的方式自动解决冲突。

总结一下，多或配置的主要优点有：① 增加主节点的容错性，一个主节点挂了不会影响其他主节点继续服务；② 可以在多个节点上执行写请求，分担写负载的压力；③ 写请求可以路由到邻近的主节点以减少响应时间。主要缺点就是它太复杂了，容易产生数据冲突。

## 无主复制
单主复制、多主复制都是这样的想法：客户端向一个主节点发送写请求，而数据库系统负责将写入复制到其他副本。主节点决定写入的顺序，而从节点按相同顺序应用主节点的写入。一些数据存储系统采用不同的方法，放弃主节点的概念，并允许任何副本直接接受来自客户端的写入。

**无主复制的主要思想是**，客户端不仅向一个节点发送写请求，而是将请求发送到多个节点（某些情况下甚至会发送给所有节点），一旦得到一些节点的确认信息就认为这次写入成功了。读取数据时，客户端也不止会从一个节点读取数据，而是将读请求发送给多个节点，获取数据和数据的版本号。
> 这里有两种方式，第一种是客户端直接向多个副本发送请求；第二种是引入一个协调节点，客户端将请求发送给协调节点，再由协调节点充当客户端的角色发送请求和接收回复，最后返回给真正的客户端。

由于执行写请求时一般不会等待所有副本的成功写入回复，那么就可能会存在部分节点未写入成功或者根本没有发送写请求给它，这样一来客户端收到的多个读请求回复里面就可能包含过期的数据，所以需要一种方法能让返回的多个数据中一定存在最新的（也就是版本号最大的）。**这种方法就是 Quorum 机制（法定人数机制）**：
> 假设总共有 $N$ 个副本，执行写请求时，当客户端（或协调节点）至少收到 $W$ 个副本成功写入回复后才认为此次写入是成功的；执行读请求时，需要至少从 $R$ 个节点上读取数据，那么只要 $W + R > N$，就能保证读请求返回的数据中一定包含先前写入的最新数据。

尽管上述机制能让客户端鉴别出最新的数据，系统依然需要修复这些不一致，在亚马逊 Dynamo 架构中有两种修复方法：
* **读修复（read repair）**。既然客户端能够鉴别出旧的数据，那么就可以由客户端在收到读请求回复后向拥有旧数据的副本发起一个带有新数据的写请求，以此来更新副本的数据。
* **反熵过程（anti-entropy process）**。反熵过程会新建一个后台进程来修复数据，该进程不断查找副本之间的数据差异，并将任何缺少或陈旧的数据从一个副本复制到另一个副本。反熵过程只保证各个副本的数据最终一致，不保证写入的顺序性。Dynamo 使用了{% post_link "CAP & BASE" 梅克尔树（merkle tree）%}来验证数据是否有不一致。