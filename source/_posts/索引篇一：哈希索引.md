---
title: 索引篇一：哈希索引
date: 2022-06-29 18:40:47
tags:
- 可拓展哈希
- 索引
categories:
- [索引]
math: true
sticky: 1
---


## 哈希函数
本节内容是，如何选择一个好的哈希函数。一个理想的哈希函数能够将 search key 的值均匀地映射到各个 bucket 中，很多时候无法提前预知 search key 会取哪些值，所以功夫主要在哈希函数的选择上，一般就可能要具有如下的特质：
* <u>映射均匀</u>。尽管无法精确知道 search key 会取哪些值，但可以能预知所有可能的取值（比如具有长度上限的字符串，整数等），那么只要保证该哈希函数能够将这一集合均匀地映射到每一个 bucket 即可。需要明白，这个集合中各元素出现的频率并不一定是相同的，需要考虑到频率。比如大学里的人年龄区间为 [14-80]，但 [20-30] 的频率远远大于其他区间。
* <u>映射随机</u>。哈希值的计算不能跟 search key 取值的任何外部可见性，比如字符顺序等，产生关联，这个不好理解，具体看下面例子。

如图 1 是一个静态哈希的例子：
![图 1](/img/hash_indices/1.jpg)

上图中，索引的 search key 为 ID，哈希函数为 ID 各位数之和模 8，共有 8 个哈希 bucket，每个的大小为 2，而且该 instructor 表是以 dept_name 顺序存储的，所以这是一个 secondary index 结构。图中展示的是已经映射完成情况，其中 bucket 5 被映射了 4 个值，超出了容量，所以分配了一个 overflow bucket.

<font color=red>现在重新映射 instructor 表，看看如何选取哈希函数</font>。假设以 dept_name 为 search key，哈希函数为取 dept_name 的第一个字符，它处于 26 个字母的第几位，就将它映射到第几个 bucket 中（当然本例 bucket 数量需要增加到 26）。该哈希函数虽然简单，**却并不满足映射均匀**，因为在 dept_name 所有可能的取值中，以 B、R 开头的 dept_name 要多于 Q 和 X，这会导致 bucket 2 和 18 的元素远多于 bucket 17 和 24 中的元素。再假设，以 salary 为 search key，哈希函数为将薪水区间分为 10 份，比如 [30001, 40000], [40001, 50000], ..., **该函数均匀（均分了薪水区间），但却不满足随机**，因为薪水处于区间 [60001, 70000] 的人数远多于 [30001, 40000] 的人数。


## 可拓展哈希
表的记录数量在一段时间内既可能变得很大，也可能很小，静态哈希索引结构不适应这样的变化。单单考虑表的大小增长，静态哈希索引将有如下方式可以应对：
* 不额外操作。那么随着记录的增多，overflow bucket 的数量剧增，各种操作将会变得很慢。
* 提前分配空间。该表的增长范围不太可能预知，那么很可能只能是扬汤止沸或者过犹不及（浪费空间）。
* rehashing. 非常费时，很可能导致索引在一段时间内不可用。

因此，哈希表能够随着记录的增长而增长，缩小而缩小的技术被设计出来，称为 dynamic hashing. 其中一种广泛使用的动态哈希是可拓展哈希（extendible hashing）。

总的来说，可拓展哈希通过合并某些空的 bucket 或者分裂某个溢出的 bucket 来应对 search key 值得减少和增长。可拓展哈希依然会存在 rehashing，但每一次只有一个 bucket 中的记录会被重新映射，开销可以接受。

<br>

<font color=dark-green>可拓展哈希的数据结构</font>
![图 2](/img/hash_indices/2.jpg)
我们依然按照上面的原则选取哈希函数，可拓展哈希的哈希函数将 search key 的值映射为二进制串（一般 32 位），如上图，search key 为 dept_name. **那如何将具体的哈希值与 bucket 绑定呢？**
![图 3](/img/hash_indices/3.jpg)
可拓展哈希采用这样的方式，如上图，左边的 bucket address table 又可以称为目录页，其中存储的是指向 bucket 的指针，右边的 bucket 是实际存储记录的结构。总的来说，可拓展哈希根据哈希值的某几位二进制来决定将某个 search key 值映射到哪一个 bucket 中。**如何决定使用哪几位呢？**目录页使用一个全局的 $i$ 来决定使用的二进制串长度（global length），图中展示的是前缀，从最高位开始，而在实现中，为了方便，常常使用后缀，从最后一位开始，后面统一使用前缀。同时每个 bucket 还记录本地实际使用的位数 $i_j$（local length），满足 $i >= i_j$。在同一个 bucket 中的记录，其 search key 值的高 $i_j$ 位都相同，为什么这样先不管，后面会逐步清晰。初始情况下 $i = 1, i_j = 1$.

<br>

<font color=dark-green>可拓展哈希的查询和更新操作</font>
下面通过查询（lookup）、插入（insertion）和删除（deletion）几个操作，来理解可拓展哈希的运作机理。

**首先是查询**。第一步是通过哈希函数计算哈希值 $val = h(Key)$，然后取该值的高 $i$ 位，<font color=red>得到目录页的下标（十进制）</font>，再根据该下标得到目录条目，该条目含有指针指向具体的 bucket. 假设当前的 global length 为 2，key = biology，如图 2，最高两位为 00，所以目录页的下标为 0，其指向 bucket 1. 然后具体的查找过程在 bucket 中执行。

**然后是插入**。先执行上面描述的查询过程，找到具体的 bucket，不妨设为 $j$，如果 bucket 还有剩余的空间，则将记录插入到该 bucket，如果 bucket 已经满了，将要执行分裂操作（split），将该 bucket 中的记录 rehash. <font color=red>分裂操作做了什么？</font>当 bucket $j$ 满了，说明 $i_j$ 太小了，search key 中具有相同前缀（高 $i_j$ 位）的太多，区分度不够，需要增加位数，以将部分记录散列到其他的 bucket 中，有如下两种可能：
* <u>如果当前 $i=i_j$</u>，需要先增加目录页。通过 $i=i+1$，增加新的一位参加映射，目录页数量就能加倍（ $2^{i+1}$）。增加的一倍的目录项都是空的（没有指向具体的 bucket），所以，会将这些新增的目录项指向与他们高 $i$ 位相同的目录项所指向的 bucket，如图 3 的 01 和 00 都指向同一个 bucket（即表示新增的一位在大多数目录项中还未用上）。<font color=red>此时，可以安全地 rehashing 了</font>。假设 bucket $j$ 中记录的 search key 都有前缀 $b_1b_2b_3$，当 $i_j=i_j+1$ 后，新的前缀有两种可能，$b_1b_2b_30$ 和 $b_1b_2b_31$，我们让具有前者前缀的 search key 依旧映射到 bucket $j$，而后者则会被映射到新增的目录项所指的 bucket，如上面上述，该目录项依旧指向 bucket $j$，所以，需要分配一个新的 bucket，让该目录项指向它。所以 bucket $j$ 中的记录会有一部分被映射到新分配的 bucket 中。然后再次哈希待插入的记录，将其插入哈希值所指的 bucket 中。最后增加这两个 bucket 的 local length.
* <u>如果当前 $i > i_j$</u>，若是该种情况，则不需要再增加目录项，可以直接 rehashing bucket $j$，和上面描述的过程一样（红色字体开始）。

下面通过一个例子阐述其插入过程，search key 如图 2 所示。
![图 4](/img/hash_indices/4.jpg)
假设可拓展哈希的初始情况如图 4，此时 $i, i_1, i_2$ 都为 1，，已经有三个记录映射到了 bucket 中。现在插入记录（22222, Einstein, Physics, 95000），因为 $h(Physics)$ 的最高位为 1，需要将其插入 bucket 2 中。而现在 bucket 2 已经满了，且 $i_2 == i$，所以需要先增加 $i$，让目录项翻倍，然后 rehash bucket 2 中的记录，最后插入新记录，结果如图 5：
![图 5](/img/hash_indices/5.jpg)
可以看到，11，01 是新增的目录项，原二进制串 '1' 指向的 bucket 2 被分裂了，一部分记录被映射到新分配的 bucket 3 中（由 11 指向），新记录插入了 bucket 2 中。而对于 01，新增的 1 位还没用上，所以指向了与它具有相同前缀的 00 目录项所指向的 bucket.

**最后是删除**，同样先通过查找操作找到 bucket，假设位 $j$，然后在 bucket $j$ 中查找指定的记录，若未找到，不做任何操作。若找到了，删除该记录。<font color=red>删除后，bucket 可能为空，若为空，则可以执行合并操作（coalescing）</font>. 合并操作是当 $i>j$ 时对 bucket $j$ 执行分裂操作的逆操作，即回收（释放）bucket $j$，让指向 bucket $j$ 的目录项指向其他 bucket，设为 $p$. 寻找 bucket $p$ 是一个递归的过程，如图 6：
![图 6](/img/hash_indices/6.jpg)

图中黄色所示的 bucket 删除后为空。左边和右边是两种不同的情况。<font color=red>左边</font>是该变空的 bucket 释放后，目录项指向新的 bucket，这个 bucket 所具备的特点是，local length 比原先小 1，并且，这两个目录项拥有相同的前缀，前缀长度刚好是这个新 bucket 的 local length. <font color=red>右边</font>，bucket 变空后，释放，然后按照左边那样找新的 bucket，但发现它们都已经变空释放了，所以就一路找到了 local length 为 1 的 bucket，两个目录项的前缀当然还是一样的，只不过前缀的长度为 1 了。所以这是一个递归的过程。

另外，当太多的的 bucket 变空后会被释放，所有剩余的 bucket 的 local length 的长度都小于目录页的 global length，就可以将目录页减半，即 global length 减少 1，释放内存，如图 6 右边。


## 总结
可拓展哈希既可以用在内存中存储数据，也可以用作磁盘数据索引结构。当用作磁盘索引结构时，bucket 是一段连续的空间，比如 4KB，里面插入了若干条记录，整个 bucket 会作为一个整体写入磁盘，读出时，再将这段空间解析为 bucket 数据结构（内存中），进行增删改查：

```C++
class Bucket {
    // function members (not occupy space)

    // data members
    Pair<KeyType, ValType> records[MAX_NUM]
}

int WriteToDisk(Bucket* bucket) {
    return io.write((char*)bucket, sizeof(bucket))
}

void ReadFromDisk(Bucket* bucket, uint32_t bucket_id) {
    char buffer[4096];
    io.seek(bucket_id * 4096)
    io.read(buffer);
    bucket = reinterpret<Bucket*>(buffer)
}
```

下面是书中对可拓展哈希的评价，不想翻译了，直接看原文吧：

**Static Hashing versus Dynamic Hashing**
> We now examine the advantages and disadvantages of extendable hashing, compared with static hashing. The main advantage of extendable hashing is that performance does not degrade as the file grows. Furthermore, there is minimal space overhead. Although the bucket address table incurs additional overhead, it contains one pointer for each hash value for the current prefix length. This table is thus small. The main space saving of extendable hashing over other forms of hashing is that no buckets need to be reserved for future growth; rather, buckets can be allocated dynamically.

> A disadvantage of extendable hashing is that lookup involves an additional level of indirection, since the system must access the bucket address table before accessing the bucket itself. This extra reference has only a minor effect on performance. Although the hash structures that we discussed in Section 24.5.1 do not have this extra level of indirection, they lose their minor performance advantage as they become full. A fur- ther disadvantage of extendable hashing is the cost of periodic doubling of the bucket address table.

> The bibliographical notes also provide references to another form of dynamic hash- ing called linear hashing, which avoids the extra level of indirection associated with extendable hashing, at the possible cost of more overflow buckets.

<br>

**Comparison of Ordered Indexing and Hashing**
> We have seen several ordered-indexing schemes and several hashing schemes. We can organize files of records as ordered files by using index-sequential organization or B+- tree organizations. Alternatively, we can organize the files by using hashing. Finally, we can organize them as heap files, where the records are not ordered in any particular way.

> Each scheme has advantages in certain situations. A database-system implementor could provide many schemes, leaving the final decision of which schemes to use to the database designer. However, such an approach requires the implementor to write more code, adding both to the cost of the system and to the space that the system occupies.

> Most database systems support B+-trees for indexing disk-based data, and many databases also support B+-tree file organization. <u>However</u>, most databases do not sup- port hash file organizations or hash indices for disk-based data. <u>One of the important reasons</u> is the fact that many applications benefit from support for range queries. <u>A second reason</u> is the fact that B+-tree indices handle relation size increases gracefully, via a series of node splits, each of which is of low cost, in contrast to the relatively high cost of doubling of the bucket address table, which extendable hashing requires. <u>Another reason</u> for preferring B+-trees is the fact that B+-trees give good worst-case bounds for deletion operations with duplicate keys, unlike hash indices.

> However, hash indices are used for in-memory indexing, if range queries are not common. In particular, they are widely used for creating temporary in-memory indices while processing join operations using the hash-join technique, see {% post_link "查询处理篇：Join 操作" %}.





